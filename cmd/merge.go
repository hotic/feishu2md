package main

import (
	"fmt"
	"html"
	"io/fs"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"time"

	"github.com/urfave/cli/v2"
)

type MergeOpts struct {
	inputDir   string
	outputDir  string
	filename   string
	configPath string
	original   bool
}

var mergeOpts = MergeOpts{}

// getMergeCommand returns the merge command definition
func getMergeCommand() *cli.Command {
	return &cli.Command{
		Name:  "merge",
		Usage: "Merge all .md files from input directory into a single file",
		Flags: []cli.Flag{
			&cli.StringFlag{
				Name:        "config",
				Aliases:     []string{"c"},
				Value:       "",
				Usage:       "Path to config file (defaults to config.yml in current directory)",
				Destination: &mergeOpts.configPath,
			},
			&cli.StringFlag{
				Name:        "input",
				Aliases:     []string{"i"},
				Value:       "",
				Usage:       "Input directory containing .md files to merge (overrides config)",
				Destination: &mergeOpts.inputDir,
			},
			&cli.StringFlag{
				Name:        "output",
				Aliases:     []string{"o"},
				Value:       "",
				Usage:       "Output directory for the merged file (overrides config)",
				Destination: &mergeOpts.outputDir,
			},
			&cli.StringFlag{
				Name:        "filename",
				Aliases:     []string{"f"},
				Value:       "",
				Usage:       "Name of the merged output file (overrides config)",
				Destination: &mergeOpts.filename,
			},
			&cli.BoolFlag{
				Name:        "original",
				Usage:       "Output original (uncompacted) content without token-compact processing",
				Value:       false,
				Destination: &mergeOpts.original,
			},
		},
		Action: func(ctx *cli.Context) error {
			return handleMergeCommand()
		},
	}
}

// handleMergeCommand processes the merge command
func handleMergeCommand() error {
	// åŠ è½½é…ç½®æ–‡ä»¶
	config, err := LoadSyncConfig(mergeOpts.configPath)
	if err != nil {
		return fmt.Errorf("åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®
	inputDir := mergeOpts.inputDir
	if inputDir == "" {
		inputDir = config.Merge.InputDir
		if inputDir == "" {
			inputDir = config.Sync.OutputDir // é»˜è®¤ä½¿ç”¨ sync çš„è¾“å‡ºç›®å½•
		}
	}

	outputDir := mergeOpts.outputDir
	if outputDir == "" {
		outputDir = config.Merge.OutputDir
	}

	filename := mergeOpts.filename
	if filename == "" {
		filename = config.Merge.Filename
	}

	headerTitle := config.Merge.HeaderTitle
	if headerTitle == "" {
		headerTitle = "åˆå¹¶çš„æ–‡æ¡£é›†åˆ"
	}

	fmt.Printf("å¼€å§‹åˆå¹¶ %s ç›®å½•ä¸­çš„ .md æ–‡ä»¶...\n", inputDir)
	fmt.Printf("é…ç½®æ¥æº: %s\n", getConfigSource(mergeOpts.configPath))

	// æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(inputDir); os.IsNotExist(err) {
		return fmt.Errorf("è¾“å…¥ç›®å½•ä¸å­˜åœ¨: %s", inputDir)
	}

	// ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
	if err := os.MkdirAll(outputDir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	// æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶
	mdFiles, err := findMarkdownFiles(inputDir)
	if err != nil {
		return fmt.Errorf("æŸ¥æ‰¾ .md æ–‡ä»¶å¤±è´¥: %v", err)
	}
	if len(mdFiles) == 0 {
		return fmt.Errorf("åœ¨ç›®å½• %s ä¸­æœªæ‰¾åˆ° .md æ–‡ä»¶", inputDir)
	}

	// æŒ‰æ–‡ä»¶åæ’åºï¼ˆå¦‚æœé…ç½®å…è®¸ï¼‰
	if config.Merge.SortFiles {
		sort.Strings(mdFiles)
	}

	// åˆå¹¶æ‰€æœ‰ Markdown æ–‡ä»¶
	outputPath := filepath.Join(outputDir, filename)
	if err := mergeMarkdownFiles(mdFiles, outputPath, config.Merge, mergeOpts.original); err != nil {
		return fmt.Errorf("åˆå¹¶æ–‡ä»¶å¤±è´¥: %v", err)
	}

	fmt.Printf("âœ… æˆåŠŸåˆå¹¶ %d ä¸ªæ–‡ä»¶åˆ°: %s\n", len(mdFiles), outputPath)

	// å¦‚æœé…ç½®äº† CSV åˆå¹¶æ–‡ä»¶åï¼ˆå…¼å®¹ filename_csv ä¸ csv_filenameï¼‰ï¼Œåˆ™å¦å¤–ç”Ÿæˆä¸€ä¸ªä»…åˆå¹¶ CSV çš„ Markdown æ–‡ä»¶
	csvOutName := config.Merge.FilenameCSV
	if strings.TrimSpace(csvOutName) == "" {
		csvOutName = config.Merge.CSVFilename
	}
	if strings.TrimSpace(csvOutName) != "" {
		// æŸ¥æ‰¾ CSV æ–‡ä»¶
		csvFiles, err := findCSVFiles(inputDir)
		if err != nil {
			return fmt.Errorf("æŸ¥æ‰¾ .csv æ–‡ä»¶å¤±è´¥: %v", err)
		}
		if len(csvFiles) == 0 {
			fmt.Println("â„¹ï¸ æœªå‘ç°ä»»ä½• CSV æ–‡ä»¶ï¼Œè·³è¿‡ CSV åˆå¹¶è¾“å‡º")
			return nil
		}
		if config.Merge.SortFiles {
			sort.Strings(csvFiles)
		}

		csvOut := filepath.Join(outputDir, csvOutName)
		if err := mergeCSVFilesToMarkdown(csvFiles, csvOut, config.Merge); err != nil {
			return fmt.Errorf("åˆå¹¶ CSV ä¸º Markdown å¤±è´¥: %v", err)
		}
		fmt.Printf("âœ… æˆåŠŸåˆå¹¶ %d ä¸ª CSV åˆ°: %s\n", len(csvFiles), csvOut)
	}

	return nil
}

// getConfigSource è¿”å›é…ç½®æ–‡ä»¶çš„æ¥æºæè¿°
func getConfigSource(configPath string) string {
	if configPath != "" {
		return configPath
	}
	if _, err := os.Stat("config.yml"); err == nil {
		return "config.yml (å½“å‰ç›®å½•)"
	}
	if _, err := os.Stat("config.yaml"); err == nil {
		return "config.yaml (å½“å‰ç›®å½•)"
	}
	if _, err := os.Stat("sync_config.yaml"); err == nil {
		return "sync_config.yaml (å½“å‰ç›®å½•ï¼Œå»ºè®®é‡å‘½åä¸º config.yml)"
	}
	return "é»˜è®¤é…ç½®"
}

// findMarkdownFiles æŸ¥æ‰¾æŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰ .md æ–‡ä»¶
func findMarkdownFiles(dir string) ([]string, error) {
	var mdFiles []string

	err := filepath.WalkDir(dir, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}

		if !d.IsDir() && strings.HasSuffix(strings.ToLower(d.Name()), ".md") {
			mdFiles = append(mdFiles, path)
		}

		return nil
	})

	return mdFiles, err
}

// findCSVFiles æŸ¥æ‰¾æŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰ .csv æ–‡ä»¶
func findCSVFiles(dir string) ([]string, error) {
	var csvFiles []string

	err := filepath.WalkDir(dir, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}
		if !d.IsDir() && strings.HasSuffix(strings.ToLower(d.Name()), ".csv") {
			csvFiles = append(csvFiles, path)
		}
		return nil
	})

	return csvFiles, err
}

// mergeMarkdownFiles å°†å¤šä¸ª .md æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶
func mergeMarkdownFiles(files []string, outputPath string, mergeConfig MergeSettings, original bool) error {
	outputFile, err := os.Create(outputPath)
	if err != nil {
		return err
	}
	defer outputFile.Close()

	// å†™å…¥æ–‡ä»¶å¤´
	var header string
	if original {
		header = fmt.Sprintf(`# %s

> æ­¤æ–‡ä»¶ç”± feishu2md å·¥å…·è‡ªåŠ¨ç”Ÿæˆ`, mergeConfig.HeaderTitle)

		if mergeConfig.IncludeTimestamp {
			header += fmt.Sprintf(`
> ç”Ÿæˆæ—¶é—´: %s`, time.Now().Format("2006-01-02 15:04:05"))
		}

		header += fmt.Sprintf(`
> åŒ…å«æ–‡æ¡£æ•°é‡: %d

---

`, len(files))
	} else {
		if mergeConfig.IncludeTimestamp {
			header = fmt.Sprintf(`> ç”Ÿæˆæ—¶é—´: %s

`, time.Now().Format("2006-01-02 15:04:05"))
		} else {
			header = ""
		}
	}

	if _, err := outputFile.WriteString(header); err != nil {
		return err
	}

	// é€ä¸ªå¤„ç†æ¯ä¸ªæ–‡ä»¶
	for i, filePath := range files {
		fmt.Printf("æ­£åœ¨å¤„ç†æ–‡ä»¶ (%d/%d): %s\n", i+1, len(files), filepath.Base(filePath))

		// è¯»å–æ–‡ä»¶å†…å®¹
		content, err := os.ReadFile(filePath)
		if err != nil {
			fmt.Printf("âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ï¼Œè·³è¿‡: %s - %v\n", filePath, err)
			continue
		}

		// è·å–æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰ä½œä¸ºå¤§æ ‡é¢˜
		filename := strings.TrimSuffix(filepath.Base(filePath), ".md")

		// å†™å…¥åˆ†å‰²çº¿å’Œå¤§æ ‡é¢˜
		separator := fmt.Sprintf("\n\n---\n\n# ğŸ“„ %s\n\n", filename)
		if !original {
			separator = fmt.Sprintf("\n\n# ğŸ“„ %s\n\n", filename)
		}
		if _, err := outputFile.WriteString(separator); err != nil {
			return err
		}

		// å†™å…¥æ–‡ä»¶å†…å®¹
		contentStr := string(content)

		// å¦‚æœæ–‡ä»¶ä»¥ # å¼€å¤´ï¼Œå°†å…¶è½¬æ¢ä¸º ## ä»¥é¿å…ä¸æˆ‘ä»¬çš„å¤§æ ‡é¢˜å†²çª
		lines := strings.Split(contentStr, "\n")
		for j, line := range lines {
			if strings.HasPrefix(strings.TrimSpace(line), "#") {
				// åœ¨ç°æœ‰çš„ # å‰é¢å†åŠ ä¸€ä¸ª #
				lines[j] = "#" + line
			}
		}
		contentStr = strings.Join(lines, "\n")

		writeStr := contentStr
		if !original {
			writeStr = compactMarkdown(contentStr, mergeConfig)
		}
		if _, err := outputFile.WriteString(writeStr); err != nil {
			return err
		}

		// ç¡®ä¿æ–‡ä»¶å†…å®¹åæœ‰æ¢è¡Œ
		if !strings.HasSuffix(contentStr, "\n") {
			if _, err := outputFile.WriteString("\n"); err != nil {
				return err
			}
		}
	}

	// å†™å…¥æ–‡ä»¶å°¾
	footer := fmt.Sprintf("\n\n---\n\n> æ–‡æ¡£åˆå¹¶å®Œæˆ | æ€»è®¡ %d ä¸ªæ–‡ä»¶", len(files))

	if mergeConfig.IncludeTimestamp {
		footer += fmt.Sprintf(" | ç”Ÿæˆæ—¶é—´: %s", time.Now().Format("2006-01-02 15:04:05"))
	}

	footer += "\n"

	if original {
		if _, err := outputFile.WriteString(footer); err != nil {
			return err
		}
	}

	return nil
}

// mergeCSVFilesToMarkdown å°†å¤šä¸ª CSV æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ª Markdownï¼ˆä»¥æ ‡é¢˜ + åŸå§‹CSVä»£ç å—å½¢å¼å±•ç¤ºï¼‰
func mergeCSVFilesToMarkdown(files []string, outputPath string, mergeConfig MergeSettings) error {
	out, err := os.Create(outputPath)
	if err != nil {
		return err
	}
	defer out.Close()

	// å¤´éƒ¨ï¼ˆä»…æ—¶é—´æˆ³ï¼‰
	if mergeConfig.IncludeTimestamp {
		if _, err := out.WriteString(fmt.Sprintf("> ç”Ÿæˆæ—¶é—´: %s\n\n", time.Now().Format("2006-01-02 15:04:05"))); err != nil {
			return err
		}
	}

	for i, filePath := range files {
		fmt.Printf("æ­£åœ¨å¤„ç† CSV (%d/%d): %s\n", i+1, len(files), filepath.Base(filePath))
		title := strings.TrimSuffix(filepath.Base(filePath), filepath.Ext(filePath))
		// å¤§æ ‡é¢˜
		if _, err := out.WriteString(fmt.Sprintf("# %s\n\n", title)); err != nil {
			return err
		}

		// è¯»å– CSV åŸæ–‡å¹¶å»é™¤ UTF-8 BOM
		raw, rerr := os.ReadFile(filePath)
		if rerr != nil {
			return rerr
		}
		if len(raw) >= 3 && raw[0] == 0xEF && raw[1] == 0xBB && raw[2] == 0xBF {
			raw = raw[3:]
		}
		if _, err := out.WriteString("```csv\n"); err != nil {
			return err
		}
		if _, err := out.Write(raw); err != nil {
			return err
		}
		// ç¡®ä¿ä»¥æ¢è¡Œç»“å°¾ï¼Œå†å…³é—­ä»£ç å—
		if len(raw) == 0 || raw[len(raw)-1] != '\n' {
			if _, err := out.WriteString("\n"); err != nil {
				return err
			}
		}
		if _, err := out.WriteString("```\n\n"); err != nil {
			return err
		}
	}

	return nil
}

// ä¿æŒä»£ç å—ä¸å˜ï¼›ç§»é™¤ HRï¼›å›¾ç‰‡è½¬ [img]ï¼›é“¾æ¥è½¬ æ–‡æœ¬ [url]ï¼›è£¸ URL -> [url]ï¼›å‹ç¼©æ ‡å‡†è¡¨æ ¼
func compactMarkdown(input string, mergeConfig MergeSettings) string {
	lines := strings.Split(input, "\n")
	var out []string
	inCode := false
	fence := ""

	i := 0
	for i < len(lines) {
		line := lines[i]
		trimmed := strings.TrimSpace(line)

		// HTML è¡¨æ ¼å‹ç¼©ï¼šæ£€æµ‹ <table> ... </table>
		if !inCode && strings.Contains(strings.ToLower(trimmed), "<table") {
			// æ”¶é›†æ•´ä¸ªè¡¨æ ¼å—
			start := i
			j := i
			foundEnd := false
			for j < len(lines) {
				if strings.Contains(strings.ToLower(lines[j]), "</table>") {
					foundEnd = true
					break
				}
				j++
			}
			if foundEnd {
				tableBlock := strings.Join(lines[start:j+1], "\n")
				dict := compressHTMLTableBlock(tableBlock, mergeConfig)
				if dict != "" {
					out = append(out, dict)
					i = j + 1
					continue
				}
				// å¦‚æœæ— æ³•å‹ç¼©ï¼ŒåŸæ ·è¾“å‡º
				out = append(out, lines[start:j+1]...)
				i = j + 1
				continue
			}
			// æœªæ‰¾åˆ°é—­åˆæ ‡ç­¾ï¼Œåˆ™ç»§ç»­å¸¸è§„å¤„ç†
		}

		// ä»£ç å›´æ 
		if strings.HasPrefix(trimmed, "```") || strings.HasPrefix(trimmed, "~~~") {
			mark := trimmed[:3]
			if !inCode {
				inCode = true
				fence = mark
			} else if strings.HasPrefix(trimmed, fence) {
				inCode = false
				fence = ""
			}
			out = append(out, line)
			i++
			continue
		}

		if inCode {
			out = append(out, line)
			i++
			continue
		}

		// HR ç§»é™¤
		if isHRLine(trimmed) {
			i++
			continue
		}

		// è¡¨æ ¼å‹ç¼©
		if looksLikeTableHeader(line) && i+1 < len(lines) && isTableDelimiter(lines[i+1]) {
			i += 2 // è·³è¿‡è¡¨å¤´ä¸åˆ†éš”
			for i < len(lines) && isTableRow(lines[i]) {
				out = append(out, compressTableRow(lines[i]))
				i++
			}
			continue
		}

		processed := simplifyLine(line)
		if processed != "" {
			out = append(out, processed)
		}
		i++
	}

	return strings.Join(out, "\n")
}

func isHRLine(s string) bool {
	t := strings.TrimSpace(s)
	return t == "---" || t == "***" || t == "___"
}

func looksLikeTableHeader(s string) bool {
	return strings.Contains(s, "|") && !isTableDelimiter(s)
}

func isTableDelimiter(s string) bool {
	t := strings.TrimSpace(s)
	if !strings.Contains(t, "|") && !strings.Contains(t, "-") {
		return false
	}
	for _, ch := range t {
		if ch != '|' && ch != '-' && ch != ':' && ch != ' ' && ch != '\t' {
			return false
		}
	}
	return strings.Contains(t, "---")
}

func isTableRow(s string) bool {
	return strings.Contains(s, "|")
}

func compressTableRow(row string) string {
	r := strings.TrimSpace(row)
	r = strings.TrimPrefix(r, "|")
	r = strings.TrimSuffix(r, "|")
	parts := strings.Split(r, "|")
	cells := make([]string, 0, len(parts))
	for _, p := range parts {
		c := strings.TrimSpace(p)
		if strings.HasPrefix(c, "`") && strings.HasSuffix(c, "`") && len(c) >= 2 {
			c = strings.TrimSuffix(strings.TrimPrefix(c, "`"), "`")
		}
		cells = append(cells, c)
	}
	return strings.Join(cells, ":")
}

func simplifyLine(line string) string {
	s := line
	s = replaceImagesWithMarker(s)
	s = replaceLinksKeepText(s)
	s = replaceBareURL(s)
	// ç§»é™¤ blockquote çš„å·¥å…·è¯´æ˜ä¸æ•°é‡è¡Œ
	trimmed := strings.TrimSpace(s)
	if strings.HasPrefix(trimmed, ">") {
		t := strings.TrimSpace(strings.TrimPrefix(trimmed, ">"))
		if strings.Contains(t, "feishu2md") || strings.Contains(t, "æ­¤æ–‡ä»¶ç”±") || strings.Contains(t, "åŒ…å«æ–‡æ¡£æ•°é‡") {
			return ""
		}
	}
	return s
}

func replaceImagesWithMarker(s string) string {
	for {
		start := strings.Index(s, "![")
		if start == -1 {
			break
		}
		mid := strings.Index(s[start:], "](")
		if mid == -1 {
			break
		}
		mid = start + mid
		end := strings.Index(s[mid+2:], ")")
		if end == -1 {
			break
		}
		end = mid + 2 + end
		s = s[:start] + "[img]" + s[end+1:]
	}
	return s
}

func replaceLinksKeepText(s string) string {
	for {
		open := strings.Index(s, "[")
		if open == -1 {
			break
		}
		close := strings.Index(s[open:], "](")
		if close == -1 {
			break
		}
		close = open + close
		end := strings.Index(s[close+2:], ")")
		if end == -1 {
			break
		}
		end = close + 2 + end
		text := s[open+1 : close]
		s = s[:open] + text + " [url]" + s[end+1:]
	}
	return s
}

func replaceBareURL(s string) string {
	for {
		idx := strings.Index(s, "http://")
		idxs := strings.Index(s, "https://")
		if idx == -1 || (idxs != -1 && idxs < idx) {
			idx = idxs
		}
		if idx == -1 {
			break
		}
		end := idx
		for end < len(s) {
			ch := s[end]
			if ch == ' ' || ch == ')' || ch == ']' || ch == '"' || ch == '\n' {
				break
			}
			end++
		}
		s = s[:idx] + "[url]" + s[end:]
	}
	return s
}

// ---------- HTML Table compaction ----------
func compressHTMLTableBlock(tableHTML string, mergeConfig MergeSettings) string {
	// Extract <tr> rows
	trRe := regexp.MustCompile(`(?is)<tr[^>]*>(.*?)</tr>`)
	tdRe := regexp.MustCompile(`(?is)<td[^>]*>(.*?)</td>`)
	brRe := regexp.MustCompile(`(?is)<br\s*/?>`)
	tagRe := regexp.MustCompile(`(?is)<[^>]+>`) // strip any remaining tags

	// Helper to clean cell text
	clean := func(s string) string {
		s = brRe.ReplaceAllString(s, " ")
		s = tagRe.ReplaceAllString(s, "")
		s = html.UnescapeString(s)
		s = strings.ReplaceAll(s, "**", "")
		s = strings.TrimSpace(s)
		// trim outer backticks
		if strings.HasPrefix(s, "`") && strings.HasSuffix(s, "`") && len(s) >= 2 {
			s = strings.TrimSuffix(strings.TrimPrefix(s, "`"), "`")
		}
		return s
	}

	// Build table: slice of rows
	var rows [][]string
	for _, m := range trRe.FindAllStringSubmatch(tableHTML, -1) {
		inner := m[1]
		var cells []string
		for _, c := range tdRe.FindAllStringSubmatch(inner, -1) {
			cells = append(cells, clean(c[1]))
		}
		// skip empty rows
		nonEmpty := false
		for _, c := range cells {
			if strings.TrimSpace(c) != "" {
				nonEmpty = true
				break
			}
		}
		if nonEmpty {
			rows = append(rows, cells)
		}
	}

	if len(rows) == 0 {
		return ""
	}

	// Detect header keywords to decide grouping strategy
	hasHeader := false
	headerKeys := mergeConfig.GroupHeaderKeywords
	if len(rows) > 0 {
		headerJoined := strings.Join(rows[0], " ")
		cnt := 0
		for _, k := range headerKeys {
			if strings.Contains(headerJoined, k) {
				cnt++
			}
		}
		if cnt >= 2 {
			hasHeader = true
		}
	}

	// If looks like category table with 3-4 cols, group by first col
	if hasHeader {
		groupOrder := []string{}
		itemsByGroup := map[string][]string{}
		currentGroup := ""

		for idx, row := range rows {
			// skip header row
			if idx == 0 {
				continue
			}
			// Identify group/code/name by column count
			g, code, cn := "", "", ""
			if len(row) >= 4 {
				g, code, cn = row[0], row[1], row[2]
			} else if len(row) == 3 {
				// likely no group cell due to rowspan
				g, code, cn = "", row[0], row[1]
			} else if len(row) == 2 {
				g, code = "", row[0]
				cn = row[1]
			} else {
				continue
			}

			if strings.TrimSpace(g) != "" {
				currentGroup = g
				if _, ok := itemsByGroup[currentGroup]; !ok {
					groupOrder = append(groupOrder, currentGroup)
					itemsByGroup[currentGroup] = []string{}
				}
			}

			if currentGroup == "" {
				// can't place without a group
				continue
			}

			code = strings.TrimSpace(code)
			cn = strings.TrimSpace(cn)
			if code == "" {
				continue
			}
			item := code
			if cn != "" {
				item = fmt.Sprintf("%s(%s)", code, cn)
			}
			itemsByGroup[currentGroup] = append(itemsByGroup[currentGroup], item)
		}

		// If no groups collected, fall back to generic
		if len(itemsByGroup) == 0 {
			return genericHTMLTableToLines(rows, mergeConfig)
		}

		var b strings.Builder
		for idx, g := range groupOrder {
			it := itemsByGroup[g]
			if len(it) == 0 {
				continue
			}
			if idx > 0 {
				b.WriteString("\n")
			}
			b.WriteString(fmt.Sprintf("%s: %s", g, strings.Join(it, ", ")))
		}
		return b.String()
	}

	// Fallback: generic colon-joined rows
	return genericHTMLTableToLines(rows, mergeConfig)
}

func genericHTMLTableToLines(rows [][]string, mergeConfig MergeSettings) string {
	if len(rows) == 0 {
		return ""
	}
	// Try to detect header row and skip
	start := 0
	if looksHeaderRow(rows[0], mergeConfig.HeaderKeywords) {
		start = 1
	}
	var out []string
	for i := start; i < len(rows); i++ {
		cells := rows[i]
		vals := make([]string, 0, len(cells))
		for _, c := range cells {
			if c == "[img]" || c == "img" {
				continue
			}
			vals = append(vals, strings.TrimSpace(c))
		}
		if len(vals) == 0 {
			continue
		}
		out = append(out, strings.Join(vals, ":"))
	}
	return strings.Join(out, "\n")
}

func looksHeaderRow(cells []string, keywords []string) bool {
	if len(cells) == 0 {
		return false
	}
	joined := strings.Join(cells, " ")
	keys := keywords
	if len(keys) == 0 {
		return false
	}
	hits := 0
	for _, k := range keys {
		if strings.Contains(joined, k) {
			hits++
		}
	}
	return hits >= 1
}
